\chapter{Introduction}
In the last 20 years Graphic Processing Units (GPUs) have come a long way from having a fixed rendering pipeline used only for the purpose of computer graphics, to becoming fully capable of performing general purpose tasks. This evolution made it possible to use the raw computing power of GPUs in areas other than computer graphics such as Artificial Intelligence, Cryptocurrencies, Computational Fluid Dynamics and so on.

Though it is true that GPUs have more cores than a regular CPU\footnote{For example, high end processors such as AMD Ryzen™ Threadripper™ 3990X and AMD EPYC™ 7742 have 64 cores (allowing for 128 threads to be run), while high end graphic cards such as NVidia GeForce RTX™ 3090 have 10496 CUDA cores.} a comparison between both based purely on the count of cores is not appropriate due to the vast difference in the hardware architecture. Different algorithms can benefit to a different degree of a GPU implementation. Again due to the difference in the architecture one will not fully benefit from the computational power of the GPU simply by rewriting an existing algorithm in GPU specific API. The GPU computing model can be described as Single Instruction Multiple Threads (SIMT) meaning that threads, which are assigned to a specific task, will execute the same instruction, but on different sets of data. This makes the GPU perfect for problems which have high arithmetic intensity with low data dependencies.

\section{GPU implementation of the FEM}
Considering the potential speed benefits of a GPU implementation of the FEM, a number of articles have been written on the subject. We can outline three possible directions. First the domain must be discretized. This is the part where the GPU could be least helpful due to the nature of the problem. The problem is partially discussed in \cite{meshing}. Second, elementwise computations and assembling of global matrices are reviewed in \cite{assembling}. Given that the elementwise computations are independent of each other we can see significant gain from a GPU implementation, however this is true only if the matrices are stored in dense format. Most of the sparse matrix formats create data dependencies, which make the assembly less scalable. Last, solving of the sparse linear system produced by the method should be discussed. Arguably this is always the bottleneck of the method. For large systems iterative methods are preferred, most often Conjugate Gradient, BiConjugate Stabilized or GMRES methods are used. Since this is the most computationally intensive task, most research is done for it \cite{sparse-solvers}, \cite{matrix-vector-mult}, \cite{biconjugate}.

In particular, we are interested in a possible GPU implementation of the FEM for the Navier-Stokes equations. The Navier-Stokes equations model the flow of viscous fluids. They are used in many areas e.g. weather forecasting, modelling ocean currents, engineering, medicine, computer graphics, etc. Unfortunately a general solution for them has not been found up to this day, moreover, proving that one exists was stated as a millenium problem by the Clay Mathematics Institute. Thus numerical methods for solving the Navier-Stokes equations are needed. The aim of this work is to implement an efficient and scalable GPU algorithm for solving the Navier-Stokes equations over unstructured 2D grids. Although the presented algorithms are general purpose and could be applied for various problems, our focus will be tilted more to applications in computer graphics and the VFX industry. Usually in computer graphics performance is valued more than accuracy, as long as the result is believable. In order to achieve a given artistic vision most of the softwares used in computer graphics even allow to generate results which are not physically correct at all (e.g. water flowing upwards, negative pressure, etc. are sometimes allowed). Another requirement is that the video sequences must be produced with a fixed frame rate; the most commonly used frame rates are 24, 30, 60 FPS\footnote{The corresponding time steps for these frame rates are $\frac{1}{24}s, \frac{1}{30}s, \frac{1}{60}s$. Smaller time steps are allowed, but the intermediate results are usually thrown away.}. A classical book on fluid simulations for the purpose of computer graphics is \cite{Bridson}. According to it, the preferred methods are a combination of finite difference method and finite volume method (i.e. the marker and cell method with structured, staggered grid \cite{MAC-Grid-Original}) \footnote{For computer graphics gases and liquids are usually simulated with different algorithms. Gases are simulated with the so-called grid solver, while liquids are simulated with a FLIP solver. The reason to use different algorithms is not because they produce vastly different results from a physical standpoint, it is because of the visual appearance. Rendering images and videos, however, is out of the scope of this work. The algorithm presented here could be categorized as a grid solver, but it is applicable for simulation of liquids, as well as, gases.}. Thus we find it an interesting task to provide a FEM alternative for unstructured meshes.

Even though the literature concerning the FEM for Navier-Stokes equations is vast, there are relatively few papers about GPU implementation of it. Most of the research (e.g. \cite{GPU-Gems}, \cite{MAC-Grid-Paper}) is based around the marker and cell method initially presented in \cite{MAC-Grid-Original} \footnote{The marker and cell method could be interpreted as a very specific variant of the FEM with structured grid of $Q_{-1}Q_0$ elements.}. \cite{phdthesis-navierstokes} focuses on GPU solver for the Reynolds-averaged Navier–Stokes equations. It presents both implicit and explicit time stepping schemes using Runge-Kutta method. It touches on the topic of matrix assembly. The method of choice for solving the presented linear system is the Generalized Minimal Residual Method (GMRES) with various preconditioning techniques. The type of element is not specified. \cite{navierstokes} focuses on GPU solver for Streamline upwind pressure-stabilizing Petrov-Galerkin formulation of the incompressible Navier–Stokes equations. It uses the GPBi-CG method to directly solve the system which results from applying the FEM. The paper does not specify whether the time stepping scheme is explicit or implicit nor does it discuss the type of the chosen element.

In this work we will present three possible algorithms, based on the FEM on an unstructured grid, for solving the Navier-Stokes equations and compare them. Two of the methods use operator splitting and the other one does not. The method which seems most promising is implemented both on CPU (in C++) and GPU (in CUDA). The CPU implementation is multithreaded. The CG method for solving linear systems is presented and an additional preconditioned version is also presented with comparisons between both. Two approaches (single kernel and mega kernel) for implementing the CG method on GPU are presented and compared. The semi-Lagrangian method for solving advection problems is presented alongside with a suitable data structure which improves its performance when unstructured meshes are used. The source code which is provided also contains a straightforward implementation of matrix assembly and computation of IC0 precontitioner.

\section{Choice of elements for solving the Navier-Stokes equations}
A vast study of the FEM applied to the Navier--Stokes equations is provided in \cite{gresho-fem}. Here we shall mention the advices given with respect to the choice of elements. We start with the notation. $P_mP_n$ means that the velocity (each component) is approximated by continuous piecewise complete polynomials of degree $m$ and pressure by continuous piecewise complete polynomials of degree $n$. $P_mP_{-n}$ means that the velocity (each component) is approximated by continuous piecewise complete polynomials of degree $m$ and the pressure is approximated via piecewise-discontinuous polynomials ($C^{-1}$) of degree $n$. For quadrilaterals/hexahedra, the designation $Q_mQ_n$ means that the velocity (each component) is approximated by a continuous piecewise polynomial of degree $m$ in each direction on the quadrilateral and likewise for the pressure, except that the polynomial degree is n. Again for the same families, $Q_mP_{-n}$ indicates the same velocity approximation with a pressure approximation that is a discontinuous complete piecewise polynomial of degree $n$ (not of degree n in each direction - it is as if the pressure was to be represented on a triangle within the quadrilateral, with ``extrapolation'' as necessary). The designation $P^+$ or $Q^+$ adds some sort of ``bubble function'' to the polynomial approximation for the velocity. These are sometimes called ``enriched'' elements. In 2D, in general, quadrilaterals have better accuracy than the triangular elements (considering polynomials of the same order). Triangluar elements are recommended in case of sophisticated geometry. $Q_2P_{-1}$ isoparametric quadrilateral element is considered to be one of the most accurate elements in 2D. From the family of the triangular elements the recommended elements are $P^+_2P_1$ and $P^+_2P_{-1}$. The latter provides ``elimination'' of $u$ and $v$ at the center node and two pressures at element level, which makes it as cost effective as the $P_1P_0$ element. The $P_1P_0$ on the other hand is not recommended at all. The situation in 3D is more complicated. Should the problem require unstructured meshes, tetrahedral should be considered first, due to the high computational cost of hexahedral elements. An easy and low cost option is the $P^+_1P_1$ MINI element. Better options, however, are the $P_2P_1$ and $P_2(P_1 + P_0)$ elements. The use of hexahedral elements is discouraged, but $Q_1Q_0$, the LBB stable $Q_2P_{-1}$ and $Q_2Q_{-1}$ are some viable options.

\section{Time discretization techniques for the Navier-Stokes equations}
There are various formulations of the Navier-Stokes equations, many of them are described in \cite{gresho-fem}. Unfortunately, there is no universal numerical time differentiation approach applicable to all of the formulations. For example, for the direct approach, which we shall present in \cref{ch:fem}, only implicit schemes make sense \cite{gresho-fem}. On the other hand \cite{Chorin-operator-split} and \cite{Bridson} both propose operator splitting (also know as fractional time stepping) techniques which could be combined with explicit time differentiation schemes. The fractional time stepping techniques are also presented in \cref{ch:fem}. \cite{Chorin-operator-split} proposes fractional time stepping which splits the differential operator in time into 2 steps: advection combined with diffusion and a Pressure Poisson equation. \cite{Bridson} proposes a fractional time stepping scheme, which splits the differential operator with respect to time into 3 steps: advection, Pressure Poisson equation and diffusion equation.

\section{Goals and structure of the MSc Thesis}

We formulate the following goals for the presented MSc Thesis:
\begin{itemize}
	\item to construct a FEM-based algorithm for solving the incompressible Navier-Stokes equations using unstructured meshes, which is suitable for (though not limited to) the purposes of computer graphics; to this end our main requirements would be:
	\begin{itemize}
		\item computational efficiency;
		\item good scalability;
		\item suitability for GPU implementation i.e. high artimethic intensity with low data dependencies;
		\item stability;
	\end{itemize}
	\item to conduct numerical experiments, based on a classical model problem (the DFG benchmark \cite{dfg-problem}), in order to study the scalability and effectiveness of the proposed method both on CPU and GPU;
	\item to outline some of the possible pros and cons of a GPU implementation;
	\item to outline directions for further development of the subject.
\end{itemize}
The MSc thesis is structured as follows. \cref{ch:fem} presents the differential formulation of the problem and compares three different finite element formulations, which can be used to solve it. Two of them split the differential operator in time and the other one is a direct approach. The CSR sparse matrix format is presented, CG, PCG and semi-Lagrangian methods are outlined. \cref{ch:implementation-details} presents implementation details about the algorithms used to solve the finite element formulations presented in \cref{ch:fem}. It shows how the algorithms outlined in \cref{ch:fem} are multithreaded on CPU and on GPU and comparison between the two is presented. \cref{ch:stastical-data} presents an extended version of the statistical data presented in \cref{ch:implementation-details}. \cref{ch:grid-sync} provides an implementation of GPU synchronization primitive used by CG method. Older GPUs need it in order to implement the CG method efficiently.

\section{Source Code}
The source code for this work is free and can be found at GitHub.
\begin{itemize}
	\item For the aim of this work a general purpose library for solving linear equations with sparse matrices was written. It can be found at \url{https://github.com/vasil-pashov/sparse_matrix_math}\footnote{Check the develop branch of the repo for the latest changes.}.
	\item The FEM implementation can be found at \url{https://github.com/vasil-pashov/Navier_Stokes_FEM}
\end{itemize}